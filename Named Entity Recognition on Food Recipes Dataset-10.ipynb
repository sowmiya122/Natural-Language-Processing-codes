{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "519d6f99",
   "metadata": {},
   "source": [
    "## Lab10.Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5b1b59",
   "metadata": {},
   "source": [
    "### 225229138-Sowmiya B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64674da8",
   "metadata": {},
   "source": [
    "## Exercise:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dfda945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd50bcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1=\"Rajkumar said on Monday that WASHINGTON -- In the wake of a string of abuses by New York Police officersin the 1990's, Loretta E.Lynch, the top federal prosecutor in Brooklyn, spoke forcefully abouth the pain of a broken trust that African-Americans felt and said the responsibility for repairing generations of miscommunication and mistrust fell to law enforcement.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be7aa858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Rajkumar said on Monday that WASHINGTON -- In the wake of a string of abuses by New York Police officersin the 1990's, Loretta E.Lynch, the top federal prosecutor in Brooklyn, spoke forcefully abouth the pain of a broken trust that African-Americans felt and said the responsibility for repairing generations of miscommunication and mistrust fell to law enforcement.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f9db787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\1mscdsa38\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('maxent_ne_chunker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "639674b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\1mscdsa38\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\1mscdsa38\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\1mscdsa38\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d71922c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tree('PERSON', [('Rajkumar', 'NNP')])]\n"
     ]
    }
   ],
   "source": [
    "tokens=word_tokenize(sentence1)\n",
    "tags=pos_tag(tokens)\n",
    "ne_tree=ne_chunk(tags)\n",
    "print(ne_tree[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06e62a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "ne_tree=ne_chunk(pos_tag(word_tokenize(sentence1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "556fda75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(PERSON Rajkumar/NNP)\n",
      "('said', 'VBD')\n",
      "('on', 'IN')\n",
      "('Monday', 'NNP')\n",
      "('that', 'IN')\n",
      "(ORGANIZATION WASHINGTON/NNP)\n",
      "('--', ':')\n",
      "('In', 'IN')\n",
      "('the', 'DT')\n",
      "('wake', 'NN')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('string', 'NN')\n",
      "('of', 'IN')\n",
      "('abuses', 'NNS')\n",
      "('by', 'IN')\n",
      "(GPE New/NNP York/NNP)\n",
      "('Police', 'NNP')\n",
      "('officersin', 'IN')\n",
      "('the', 'DT')\n",
      "('1990', 'CD')\n",
      "(\"'s\", 'POS')\n",
      "(',', ',')\n",
      "(PERSON Loretta/NNP E.Lynch/NNP)\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('top', 'JJ')\n",
      "('federal', 'JJ')\n",
      "('prosecutor', 'NN')\n",
      "('in', 'IN')\n",
      "(GPE Brooklyn/NNP)\n",
      "(',', ',')\n",
      "('spoke', 'VBD')\n",
      "('forcefully', 'RB')\n",
      "('abouth', 'VBZ')\n",
      "('the', 'DT')\n",
      "('pain', 'NN')\n",
      "('of', 'IN')\n",
      "('a', 'DT')\n",
      "('broken', 'JJ')\n",
      "('trust', 'NN')\n",
      "('that', 'IN')\n",
      "('African-Americans', 'NNP')\n",
      "('felt', 'VBD')\n",
      "('and', 'CC')\n",
      "('said', 'VBD')\n",
      "('the', 'DT')\n",
      "('responsibility', 'NN')\n",
      "('for', 'IN')\n",
      "('repairing', 'VBG')\n",
      "('generations', 'NNS')\n",
      "('of', 'IN')\n",
      "('miscommunication', 'NN')\n",
      "('and', 'CC')\n",
      "('mistrust', 'NN')\n",
      "('fell', 'VBD')\n",
      "('to', 'TO')\n",
      "('law', 'NN')\n",
      "('enforcement', 'NN')\n",
      "('.', '.')\n"
     ]
    }
   ],
   "source": [
    "for i in ne_tree:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b3fc6f",
   "metadata": {},
   "source": [
    "### Question-1:Count and print the number of person,location and organization in the given sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e351c46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Counter({'Rajkumar': 1, 'NNP': 1})]\n",
      "[Counter({'WASHINGTON': 1, 'NNP': 1})]\n",
      "[Counter({'New': 1, 'NNP': 1}), Counter({'York': 1, 'NNP': 1})]\n",
      "[Counter({'Loretta': 1, 'NNP': 1}), Counter({'E.Lynch': 1, 'NNP': 1})]\n",
      "[Counter({'Brooklyn': 1, 'NNP': 1})]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sentence1))):\n",
    "    if hasattr(chunk, 'label'):\n",
    "        print([Counter(label) for label in chunk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c75b9d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rajkumar Counter({'NNP': 1})\n",
      "WASHINGTON Counter({'NNP': 1})\n",
      "New Counter({'NNP': 2})\n",
      "Loretta Counter({'NNP': 2})\n",
      "Brooklyn Counter({'NNP': 1})\n"
     ]
    }
   ],
   "source": [
    "tags = nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sentence1)))\n",
    "for chunk in tags:\n",
    "    if hasattr(chunk, 'label') and chunk.label() != 'S': \n",
    "        label, entity = zip(*chunk)\n",
    "        print(label[0], Counter(entity))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c36d01",
   "metadata": {},
   "source": [
    "### Question 2:observe the results. Does named entity \"Police Officers\" get recognized?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd7ea966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rajkumar', 'WASHINGTON', 'New York', 'Loretta E.Lynch', 'Brooklyn']\n"
     ]
    }
   ],
   "source": [
    "my_sent = \"Rajkumar said on Monday that WASHINGTON -- In the wake of a string of abuses by New York Police officersin the 1990's, Loretta E.Lynch, the top federal prosecutor in Brooklyn, spoke forcefully abouth the pain of a broken trust that African-Americans felt and said the responsibility for repairing generations of miscommunication and mistrust fell to law enforcement.\"\n",
    "word = nltk.word_tokenize(my_sent)\n",
    "pos_tag = nltk.pos_tag(word)\n",
    "chunk = nltk.ne_chunk(pos_tag)\n",
    "grammar = \"NP: {<NN><NNS>}\"\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "result = cp.parse(chunk)\n",
    "NE = [ \" \".join(w for w, t in ele) for ele in result if isinstance(ele, nltk.Tree)]\n",
    "print (NE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04e0f15",
   "metadata": {},
   "source": [
    "### WRITE A REGULAR EXPRESSION PATTER TO DETECT THIS.YOU WILL NEED NLTK.REGEXPPARSER CLASS TO DEFINE PATTERN AND PARSE TERMS TO DETECT PATTERNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e018c48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rajkumar', 'WASHINGTON', 'the wake', 'a string', 'New York', 'Loretta E.Lynch', 'the top federal prosecutor', 'Brooklyn', 'the pain', 'a broken trust', 'the responsibility']\n"
     ]
    }
   ],
   "source": [
    "grammar = \"NP: {<DT><JJ>*<NN>}\"\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "result = cp.parse(chunk)\n",
    "NE = [ \" \".join(w for w, t in ele) for ele in result if isinstance(ele, nltk.Tree)]\n",
    "print (NE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe149ccc",
   "metadata": {},
   "source": [
    "### Question 3: Does the named entity ,'The Top Federal Prosecutor' get recognized?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1646356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tree('PERSON', [('Rajkumar', 'NNP')]), ('said', 'VBD'), ('on', 'IN'), ('Monday', 'NNP'), ('that', 'IN'), Tree('ORGANIZATION', [('WASHINGTON', 'NNP')]), ('--', ':'), ('In', 'IN'), Tree('NP', [('the', 'DT'), ('wake', 'NN')]), ('of', 'IN'), Tree('NP', [('a', 'DT'), ('string', 'NN')]), ('of', 'IN'), ('abuses', 'NNS'), ('by', 'IN'), Tree('GPE', [('New', 'NNP'), ('York', 'NNP')]), ('Police', 'NNP'), ('officersin', 'IN'), ('the', 'DT'), ('1990', 'CD'), (\"'s\", 'POS'), (',', ','), Tree('PERSON', [('Loretta', 'NNP'), ('E.Lynch', 'NNP')]), (',', ','), Tree('NP', [('the', 'DT'), ('top', 'JJ'), ('federal', 'JJ'), ('prosecutor', 'NN')]), ('in', 'IN'), Tree('GPE', [('Brooklyn', 'NNP')]), (',', ','), ('spoke', 'VBD'), ('forcefully', 'RB'), ('abouth', 'VBZ'), Tree('NP', [('the', 'DT'), ('pain', 'NN')]), ('of', 'IN'), Tree('NP', [('a', 'DT'), ('broken', 'JJ'), ('trust', 'NN')]), ('that', 'IN'), ('African-Americans', 'NNP'), ('felt', 'VBD'), ('and', 'CC'), ('said', 'VBD'), Tree('NP', [('the', 'DT'), ('responsibility', 'NN')]), ('for', 'IN'), ('repairing', 'VBG'), ('generations', 'NNS'), ('of', 'IN'), ('miscommunication', 'NN'), ('and', 'CC'), ('mistrust', 'NN'), ('fell', 'VBD'), ('to', 'TO'), ('law', 'NN'), ('enforcement', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "parse = cp.parse(tags)\n",
    "print(parse[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d76ae6",
   "metadata": {},
   "source": [
    "### Write a regular expression pattern to detect this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c3d0f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rajkumar', 'WASHINGTON', 'the wake', 'a string', 'New York', 'Loretta E.Lynch', 'Brooklyn', 'the pain', 'the responsibility']\n"
     ]
    }
   ],
   "source": [
    "grammar = \"NP: {<DT><JACJ>*<NN>}\"\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "result = cp.parse(chunk)\n",
    "NE = [ \" \".join(w for w, t in ele) for ele in result if isinstance(ele, nltk.Tree)]\n",
    "print (NE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ba3001",
   "metadata": {},
   "source": [
    "## Exercise 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f19498",
   "metadata": {},
   "source": [
    "### Extract All Named Entities From The Following Text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58ca60b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence2=\"European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd0dfd35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b130ef",
   "metadata": {},
   "source": [
    "### Question1: Observe The Output. Does Your Code Recognize The NE Showns in Bold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "248a4c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tree('GPE', [('European', 'JJ')]), ('authorities', 'NNS'), ('fined', 'VBD'), Tree('PERSON', [('Google', 'NNP')]), ('a', 'DT'), ('record', 'NN'), ('$', '$'), ('5.1', 'CD'), ('billion', 'CD'), ('on', 'IN'), ('Wednesday', 'NNP'), ('for', 'IN'), ('abusing', 'VBG'), ('its', 'PRP$'), ('power', 'NN'), ('in', 'IN'), ('the', 'DT'), ('mobile', 'JJ'), ('phone', 'NN'), ('market', 'NN'), ('and', 'CC'), ('ordered', 'VBD'), ('the', 'DT'), ('company', 'NN'), ('to', 'TO'), ('alter', 'VB'), ('its', 'PRP$'), ('practices', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "token=word_tokenize(sentence2)\n",
    "tag=nltk.pos_tag(token)\n",
    "ne_tree=ne_chunk(tag)\n",
    "print(ne_tree[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32107eb",
   "metadata": {},
   "source": [
    "### WRITE A REGULAR EXPRESSION THAT RECOGNIZES THE ENTITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a036c2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['European', 'Google', '5.1', 'billion']\n"
     ]
    }
   ],
   "source": [
    "word = nltk.word_tokenize(sentence2)\n",
    "pos_tag = nltk.pos_tag(word)\n",
    "chunk = nltk.ne_chunk(pos_tag)\n",
    "grammar = \"NP: {<CD>}\"\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "result = cp.parse(chunk)\n",
    "NE = [ \" \".join(w for w, t in ele) for ele in result if isinstance(ele, nltk.Tree)]\n",
    "print (NE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f00558e",
   "metadata": {},
   "source": [
    "### QUESTION 2:WRITE A REGULAR EXPRESSION THAT RECOGNIZES THE ENTITY,\"THE MOBILE PHONE\" AND SIMILAR TO THIS ENTITY SUCH AS \"THE COMPANY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d098e5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['European', 'Google', 'a record', 'the mobile phone', 'the company']\n"
     ]
    }
   ],
   "source": [
    "word = nltk.word_tokenize(sentence2)\n",
    "pos_tag = nltk.pos_tag(word)\n",
    "chunk = nltk.ne_chunk(pos_tag)\n",
    "grammar = \"NP: {<DT><JJ>*<NN>}\"\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "result = cp.parse(chunk)\n",
    "NE = [ \" \".join(w for w, t in ele) for ele in result if isinstance(ele, nltk.Tree)]\n",
    "print (NE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503b0256",
   "metadata": {},
   "source": [
    "### Exercise-3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d73c01",
   "metadata": {},
   "source": [
    "In this exercise, you will extract all ingredients from the food recipes text files, \"food_recipes.txt\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be761a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"food_recipe.txt\")\n",
    "a=f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28bf6414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['1 1/2 cups dry *red wine*\\\\n',\\n\",\n",
       " \" '3 cloves *garlic*\\\\n',\\n\",\n",
       " \" '1 3/4 cups *beef broth*\\\\n',\\n\",\n",
       " \" '1 1/4 cups *chicken broth*\\\\n',\\n\",\n",
       " \" '1 1/2 tablespoons *tomato paste*\\\\n',\\n\",\n",
       " \" '1 *bay leaf*\\\\n',\\n\",\n",
       " \" '1 *sprig thyme*\\\\n',\\n\",\n",
       " \" '8 ounces *bacon* cut into 1/4 inch pieces\\\\n',\\n\",\n",
       " \" '1 tablespoon *flour*\\\\n',\\n\",\n",
       " \" '1 tablespoon *butter*\\\\n',\\n\",\n",
       " \" '4 1 inch *rib-eye steaks*\\\\n',\\n\",\n",
       " \" '1 tablespoon *bourbon whiskey*']\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1db9ceaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red wine\n",
      "garlic\n",
      "beef broth\n",
      "chicken broth\n",
      "tomato paste\n",
      "bay leaf\n",
      "sprig thyme\n",
      "bacon\n",
      "flour\n",
      "butter\n",
      "rib-eye steaks\n",
      "bourbon whiskey\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "with open(\"food_recipe.txt\") as f:\n",
    "    s = f.read()\n",
    "bold_pattern = r'\\*([^*]+)\\*'\n",
    "bold_words = re.findall(bold_pattern, s)\n",
    "for word in bold_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6157bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
