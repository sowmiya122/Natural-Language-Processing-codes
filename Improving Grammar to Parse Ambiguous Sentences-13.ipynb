{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4ae1e61",
   "metadata": {},
   "source": [
    "## Lab 13: Improving Grammar to Parse Ambiguous Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f8106a",
   "metadata": {},
   "source": [
    "### 225229138-SOWMIYA B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3fcbd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tree import Tree\n",
    "from nltk.tokenize import word_tokenize\n",
    "from IPython.display import display\n",
    "import nltk,re,pprint\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import ne_chunk\n",
    "import numpy as npt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa37f28",
   "metadata": {},
   "source": [
    "### EXERCISE-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2f02c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "Grammar_1 = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP | NP VP \n",
    "NP -> N | Det N | PRO | N N \n",
    "VP -> V NP CP | VP ADVP | V NP \n",
    "ADVP -> ADV ADV \n",
    "CP -> COMP S \n",
    "N -> 'Lisa' | 'brother' | 'peanut' | 'butter' \n",
    "V -> 'told' | 'liked' \n",
    "COMP -> 'that' \n",
    "Det -> 'her' \n",
    "PRO -> 'she' \n",
    "ADV -> 'very' | 'much'\n",
    "S -> NP VP \n",
    "NP -> NP CONJ NP | N | NP PP | Det N | N | Det N \n",
    "VP -> VP PP | VP CONJ VP | V | V \n",
    "PP -> P NP | P NP \n",
    "N -> 'Homer' | 'friends' | 'work' | 'bar' \n",
    "V -> 'drank' | 'sang' \n",
    "CONJ -> 'and' | 'and'\n",
    "Det -> 'his' | 'the'\n",
    "P -> 'from' | 'in'\n",
    "S -> NP VP \n",
    "NP -> NP CONJ NP | N | N \n",
    "VP -> V ADJP \n",
    "ADJP -> ADJP CONJ ADJP | ADJ | ADV ADJ \n",
    "N -> 'Homer' | 'Marge' \n",
    "V -> 'are' \n",
    "CONJ -> 'and' | 'but'\n",
    "ADJ -> 'poor' | 'happy'\n",
    "ADV -> 'very'\n",
    "S -> NP VP | NP AUX VP \n",
    "NP -> PRO | NP CP | Det N | PRO | PRO | PRO | N |Det N\n",
    "VP -> V NP PP | V NP NP\n",
    "CP -> COMP S\n",
    "PP -> P NP \n",
    "Det -> 'the' | 'his' \n",
    "PRO -> 'he' | 'I' | 'him' \n",
    "N -> 'book' | 't' | 'sister' \n",
    "V -> 'gave' | 'given' \n",
    "COMP -> 'that'\n",
    "AUX -> 'had' \n",
    "P -> 'to'\n",
    "S -> NP VP\n",
    "NP -> PRO | Det N | Det N\n",
    "VP -> V NP PP\n",
    "PP -> P NP \n",
    "Det -> 'the' | 'his'\n",
    "PRO -> 'he' \n",
    "N -> 'book' | 'sister' \n",
    "V -> 'gave' \n",
    "P -> 'to'\n",
    "S -> NP VP\n",
    "NP -> Det ADJ N | Det ADJ ADJ N | N\n",
    "VP -> V NP|VP PP\n",
    "PP -> P NP \n",
    "Det -> 'the' | 'the'\n",
    "ADJ -> 'big' | 'tiny' | 'nerdy'\n",
    "N -> 'bully' | 'kid' | 'school'\n",
    "V -> 'punched'\n",
    "P -> 'after'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7cd7c0",
   "metadata": {},
   "source": [
    "#### 1.Examine the parser output from the previous lab. Is any of the sentences ambiguous, that is, has more than one parse tree? Pick an example and provide an explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1076c5f",
   "metadata": {},
   "source": [
    "Yes! here we have two sentences which has more than one parse tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cbee42",
   "metadata": {},
   "source": [
    "1.Homer and his friends from work drank and sang in the bar\n",
    "\n",
    "2.Lisa told her brother that she liked peanut butter very much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5acc6d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP\n",
      "    (NP (NP (N Homer)) (CONJ and) (NP (Det his) (N friends)))\n",
      "    (PP (P from) (NP (N work))))\n",
      "  (VP\n",
      "    (VP (VP (V drank)) (CONJ and) (VP (V sang)))\n",
      "    (PP (P in) (NP (Det the) (N bar)))))\n",
      "(S\n",
      "  (NP\n",
      "    (NP (N Homer))\n",
      "    (CONJ and)\n",
      "    (NP (NP (Det his) (N friends)) (PP (P from) (NP (N work)))))\n",
      "  (VP\n",
      "    (VP (VP (V drank)) (CONJ and) (VP (V sang)))\n",
      "    (PP (P in) (NP (Det the) (N bar)))))\n",
      "(S\n",
      "  (NP\n",
      "    (NP (NP (N Homer)) (CONJ and) (NP (Det his) (N friends)))\n",
      "    (PP (P from) (NP (N work))))\n",
      "  (VP\n",
      "    (VP (V drank))\n",
      "    (CONJ and)\n",
      "    (VP (VP (V sang)) (PP (P in) (NP (Det the) (N bar))))))\n",
      "(S\n",
      "  (NP\n",
      "    (NP (N Homer))\n",
      "    (CONJ and)\n",
      "    (NP (NP (Det his) (N friends)) (PP (P from) (NP (N work)))))\n",
      "  (VP\n",
      "    (VP (V drank))\n",
      "    (CONJ and)\n",
      "    (VP (VP (V sang)) (PP (P in) (NP (Det the) (N bar))))))\n"
     ]
    }
   ],
   "source": [
    "sentence5 = word_tokenize(\"Homer and his friends from work drank and sang in the bar\")\n",
    "par = nltk.ChartParser(Grammar_1)\n",
    "for i in par.parse(sentence5):\n",
    " print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5fc1a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (N Lisa))\n",
      "  (VP\n",
      "    (V told)\n",
      "    (NP (Det her) (N brother))\n",
      "    (CP\n",
      "      (COMP that)\n",
      "      (S\n",
      "        (NP (PRO she))\n",
      "        (VP\n",
      "          (VP (V liked) (NP (N peanut) (N butter)))\n",
      "          (ADVP (ADV very) (ADV much)))))))\n",
      "(S\n",
      "  (NP (N Lisa))\n",
      "  (VP\n",
      "    (V told)\n",
      "    (NP (Det her) (N brother))\n",
      "    (CP\n",
      "      (COMP that)\n",
      "      (S\n",
      "        (NP (PRO she))\n",
      "        (VP\n",
      "          (VP (V liked) (NP (N peanut)) (NP (N butter)))\n",
      "          (ADVP (ADV very) (ADV much)))))))\n",
      "(S\n",
      "  (NP (N Lisa))\n",
      "  (VP\n",
      "    (V told)\n",
      "    (NP\n",
      "      (NP (Det her) (N brother))\n",
      "      (CP\n",
      "        (COMP that)\n",
      "        (S\n",
      "          (NP (PRO she))\n",
      "          (VP\n",
      "            (VP (V liked) (NP (N peanut) (N butter)))\n",
      "            (ADVP (ADV very) (ADV much))))))))\n",
      "(S\n",
      "  (NP (N Lisa))\n",
      "  (VP\n",
      "    (V told)\n",
      "    (NP\n",
      "      (NP (Det her) (N brother))\n",
      "      (CP\n",
      "        (COMP that)\n",
      "        (S\n",
      "          (NP (PRO she))\n",
      "          (VP\n",
      "            (VP (V liked) (NP (N peanut)) (NP (N butter)))\n",
      "            (ADVP (ADV very) (ADV much))))))))\n",
      "(S\n",
      "  (NP (N Lisa))\n",
      "  (VP\n",
      "    (VP\n",
      "      (V told)\n",
      "      (NP\n",
      "        (NP (Det her) (N brother))\n",
      "        (CP (COMP that) (S (NP (PRO she)) (VP (V liked)))))\n",
      "      (NP (N peanut) (N butter)))\n",
      "    (ADVP (ADV very) (ADV much))))\n",
      "(S\n",
      "  (NP (N Lisa))\n",
      "  (VP\n",
      "    (VP\n",
      "      (V told)\n",
      "      (NP\n",
      "        (NP (Det her) (N brother))\n",
      "        (CP\n",
      "          (COMP that)\n",
      "          (S (NP (PRO she)) (VP (V liked) (NP (N peanut))))))\n",
      "      (NP (N butter)))\n",
      "    (ADVP (ADV very) (ADV much))))\n",
      "(S\n",
      "  (NP (N Lisa))\n",
      "  (VP\n",
      "    (VP\n",
      "      (V told)\n",
      "      (NP (Det her) (N brother))\n",
      "      (CP\n",
      "        (COMP that)\n",
      "        (S (NP (PRO she)) (VP (V liked) (NP (N peanut) (N butter))))))\n",
      "    (ADVP (ADV very) (ADV much))))\n",
      "(S\n",
      "  (NP (N Lisa))\n",
      "  (VP\n",
      "    (VP\n",
      "      (V told)\n",
      "      (NP (Det her) (N brother))\n",
      "      (CP\n",
      "        (COMP that)\n",
      "        (S\n",
      "          (NP (PRO she))\n",
      "          (VP (V liked) (NP (N peanut)) (NP (N butter))))))\n",
      "    (ADVP (ADV very) (ADV much))))\n",
      "(S\n",
      "  (NP (N Lisa))\n",
      "  (VP\n",
      "    (VP\n",
      "      (V told)\n",
      "      (NP\n",
      "        (NP (Det her) (N brother))\n",
      "        (CP\n",
      "          (COMP that)\n",
      "          (S\n",
      "            (NP (PRO she))\n",
      "            (VP (V liked) (NP (N peanut) (N butter)))))))\n",
      "    (ADVP (ADV very) (ADV much))))\n",
      "(S\n",
      "  (NP (N Lisa))\n",
      "  (VP\n",
      "    (VP\n",
      "      (V told)\n",
      "      (NP\n",
      "        (NP (Det her) (N brother))\n",
      "        (CP\n",
      "          (COMP that)\n",
      "          (S\n",
      "            (NP (PRO she))\n",
      "            (VP (V liked) (NP (N peanut)) (NP (N butter)))))))\n",
      "    (ADVP (ADV very) (ADV much))))\n"
     ]
    }
   ],
   "source": [
    "sentence6 = word_tokenize(\"Lisa told her brother that she liked peanut butter very much\")\n",
    "par = nltk.ChartParser(Grammar_1)\n",
    "for i in par.parse(sentence6):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d14ce9",
   "metadata": {},
   "source": [
    "Have your parser parse this new sentence. It is covered by the grammar, therefore the parser should be able to handle it:\n",
    "\n",
    "(s12): Lisa and her friends told Marge that Homer punched the bully in the bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0022c4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (NP (N Lisa)) (CONJ and) (NP (Det her) (N friends)))\n",
      "  (VP\n",
      "    (V told)\n",
      "    (NP\n",
      "      (NP (N Marge))\n",
      "      (CP\n",
      "        (COMP that)\n",
      "        (S (NP (N Homer)) (VP (V punched) (NP (Det the) (N bully))))))\n",
      "    (PP (P in) (NP (Det the) (N bar)))))\n",
      "(S\n",
      "  (NP (NP (N Lisa)) (CONJ and) (NP (Det her) (N friends)))\n",
      "  (VP\n",
      "    (V told)\n",
      "    (NP\n",
      "      (NP\n",
      "        (NP (N Marge))\n",
      "        (CP\n",
      "          (COMP that)\n",
      "          (S\n",
      "            (NP (N Homer))\n",
      "            (VP (V punched) (NP (Det the) (N bully))))))\n",
      "      (PP (P in) (NP (Det the) (N bar))))))\n",
      "(S\n",
      "  (NP (NP (N Lisa)) (CONJ and) (NP (Det her) (N friends)))\n",
      "  (VP\n",
      "    (V told)\n",
      "    (NP\n",
      "      (NP (N Marge))\n",
      "      (CP\n",
      "        (COMP that)\n",
      "        (S\n",
      "          (NP (N Homer))\n",
      "          (VP\n",
      "            (VP (V punched) (NP (Det the) (N bully)))\n",
      "            (PP (P in) (NP (Det the) (N bar)))))))))\n",
      "(S\n",
      "  (NP (NP (N Lisa)) (CONJ and) (NP (Det her) (N friends)))\n",
      "  (VP\n",
      "    (V told)\n",
      "    (NP\n",
      "      (NP (N Marge))\n",
      "      (CP\n",
      "        (COMP that)\n",
      "        (S\n",
      "          (NP (N Homer))\n",
      "          (VP\n",
      "            (V punched)\n",
      "            (NP (Det the) (N bully))\n",
      "            (PP (P in) (NP (Det the) (N bar)))))))))\n",
      "(S\n",
      "  (NP (NP (N Lisa)) (CONJ and) (NP (Det her) (N friends)))\n",
      "  (VP\n",
      "    (V told)\n",
      "    (NP\n",
      "      (NP (N Marge))\n",
      "      (CP\n",
      "        (COMP that)\n",
      "        (S\n",
      "          (NP (N Homer))\n",
      "          (VP\n",
      "            (V punched)\n",
      "            (NP\n",
      "              (NP (Det the) (N bully))\n",
      "              (PP (P in) (NP (Det the) (N bar))))))))))\n",
      "(S\n",
      "  (NP (NP (N Lisa)) (CONJ and) (NP (Det her) (N friends)))\n",
      "  (VP\n",
      "    (V told)\n",
      "    (NP (N Marge))\n",
      "    (CP\n",
      "      (COMP that)\n",
      "      (S\n",
      "        (NP (N Homer))\n",
      "        (VP\n",
      "          (VP (V punched) (NP (Det the) (N bully)))\n",
      "          (PP (P in) (NP (Det the) (N bar))))))))\n",
      "(S\n",
      "  (NP (NP (N Lisa)) (CONJ and) (NP (Det her) (N friends)))\n",
      "  (VP\n",
      "    (V told)\n",
      "    (NP (N Marge))\n",
      "    (CP\n",
      "      (COMP that)\n",
      "      (S\n",
      "        (NP (N Homer))\n",
      "        (VP\n",
      "          (V punched)\n",
      "          (NP (Det the) (N bully))\n",
      "          (PP (P in) (NP (Det the) (N bar))))))))\n",
      "(S\n",
      "  (NP (NP (N Lisa)) (CONJ and) (NP (Det her) (N friends)))\n",
      "  (VP\n",
      "    (V told)\n",
      "    (NP (N Marge))\n",
      "    (CP\n",
      "      (COMP that)\n",
      "      (S\n",
      "        (NP (N Homer))\n",
      "        (VP\n",
      "          (V punched)\n",
      "          (NP\n",
      "            (NP (Det the) (N bully))\n",
      "            (PP (P in) (NP (Det the) (N bar)))))))))\n",
      "(S\n",
      "  (NP (NP (N Lisa)) (CONJ and) (NP (Det her) (N friends)))\n",
      "  (VP\n",
      "    (VP\n",
      "      (V told)\n",
      "      (NP\n",
      "        (NP (N Marge))\n",
      "        (CP (COMP that) (S (NP (N Homer)) (VP (V punched)))))\n",
      "      (NP (Det the) (N bully)))\n",
      "    (PP (P in) (NP (Det the) (N bar)))))\n",
      "(S\n",
      "  (NP (NP (N Lisa)) (CONJ and) (NP (Det her) (N friends)))\n",
      "  (VP\n",
      "    (VP\n",
      "      (V told)\n",
      "      (NP (N Marge))\n",
      "      (CP\n",
      "        (COMP that)\n",
      "        (S (NP (N Homer)) (VP (V punched) (NP (Det the) (N bully))))))\n",
      "    (PP (P in) (NP (Det the) (N bar)))))\n",
      "(S\n",
      "  (NP (NP (N Lisa)) (CONJ and) (NP (Det her) (N friends)))\n",
      "  (VP\n",
      "    (VP\n",
      "      (V told)\n",
      "      (NP\n",
      "        (NP (N Marge))\n",
      "        (CP\n",
      "          (COMP that)\n",
      "          (S\n",
      "            (NP (N Homer))\n",
      "            (VP (V punched) (NP (Det the) (N bully)))))))\n",
      "    (PP (P in) (NP (Det the) (N bar)))))\n",
      "(S\n",
      "  (NP (NP (N Lisa)) (CONJ and) (NP (Det her) (N friends)))\n",
      "  (VP\n",
      "    (V told)\n",
      "    (NP\n",
      "      (NP (N Marge))\n",
      "      (CP (COMP that) (S (NP (N Homer)) (VP (V punched)))))\n",
      "    (NP (NP (Det the) (N bully)) (PP (P in) (NP (Det the) (N bar))))))\n"
     ]
    }
   ],
   "source": [
    "s12 = word_tokenize(\"Lisa and her friends told Marge that Homer punched the bully in the bar\")\n",
    "par = nltk.ChartParser(Grammar_1)\n",
    "for i in par.parse(s12):\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53f1ed2",
   "metadata": {},
   "source": [
    " 3.Come up with a sentence of your own that's covered by grammar1 and have the parser parse it. Are you satisfied with the result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "837c7c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (NP (N Homer)) (CONJ and) (NP (N friends)))\n",
      "  (VP\n",
      "    (VP (V punched) (NP (Det the) (ADJ tiny) (ADJ nerdy) (N kid)))\n",
      "    (PP (P after) (NP (N school)))))\n",
      "(S\n",
      "  (NP (NP (N Homer)) (CONJ and) (NP (N friends)))\n",
      "  (VP\n",
      "    (V punched)\n",
      "    (NP (Det the) (ADJ tiny) (ADJ nerdy) (N kid))\n",
      "    (PP (P after) (NP (N school)))))\n",
      "(S\n",
      "  (NP (NP (N Homer)) (CONJ and) (NP (N friends)))\n",
      "  (VP\n",
      "    (V punched)\n",
      "    (NP\n",
      "      (NP (Det the) (ADJ tiny) (ADJ nerdy) (N kid))\n",
      "      (PP (P after) (NP (N school))))))\n"
     ]
    }
   ],
   "source": [
    "result = word_tokenize(\"Homer and friends punched the tiny nerdy kid after school\")\n",
    "par = nltk.ChartParser(Grammar_1)\n",
    "for i in par.parse(result):\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e68892e",
   "metadata": {},
   "source": [
    "Let's revisit our first three sentences from the previous lab.\n",
    "\n",
    "(s1): Marge will make a ham sandwich\n",
    "\n",
    "(s2): will Marge make a ham sandwich\n",
    "\n",
    "(s3): Homer ate the donut on the table\n",
    "\n",
    "As it is, your grammar1 does not cover them. But we can extend it with the CF rules from the three sentences' trees. Follow the steps below.\n",
    "\n",
    "a. From the three sentence trees, create a list of all production rules in them. Turn it into a set, which removes all duplicates. (Hint: use set().)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1c30f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_set = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e05ab1bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[S -> NP AUX VP,\n",
       " NP -> N,\n",
       " N -> 'Marge',\n",
       " AUX -> 'will',\n",
       " VP -> V NP,\n",
       " V -> 'make',\n",
       " NP -> Det N N,\n",
       " Det -> 'a',\n",
       " N -> 'ham',\n",
       " N -> 'sandwich']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = Tree.fromstring('(S(NP (N Marge))(AUX will)(VP (V make) (NP (Det a) (N ham) (N sandwich))))')\n",
    "s1_r = s1.productions()\n",
    "s1_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52ec3deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[S -> AUX NP VP,\n",
       " AUX -> 'will',\n",
       " NP -> N,\n",
       " N -> 'Marge',\n",
       " VP -> V NP,\n",
       " V -> 'make',\n",
       " NP -> Det N N,\n",
       " Det -> 'a',\n",
       " N -> 'ham',\n",
       " N -> 'sandwich']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2 = Tree.fromstring('(S(AUX will)(NP (N Marge))(VP (V make) (NP (Det a) (N ham) (N sandwich))))')\n",
    "s2_r = s2.productions()\n",
    "s2_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2788c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[S -> NP VP,\n",
       " NP -> N,\n",
       " N -> 'Homer',\n",
       " VP -> V NP,\n",
       " V -> 'ate',\n",
       " NP -> NP PP,\n",
       " NP -> Det N,\n",
       " Det -> 'the',\n",
       " N -> 'donut',\n",
       " PP -> 'on' NP,\n",
       " NP -> DET N,\n",
       " DET -> 'the',\n",
       " N -> 'table']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3 = Tree.fromstring('(S(NP (N Homer))(VP(V ate)(NP(NP (Det the) (N donut))(PP on  (NP (DET the) (N table))))))')\n",
    "s3_r = s3.productions()\n",
    "s3_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fc0e199",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_1r = []\n",
    "s_1r = s1_r.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5a69b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_2r = []\n",
    "s_2r = s2_r.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c07fe20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_3r = []\n",
    "s_3r = s3_r.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a84f316",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = []\n",
    "for i in s_1r:\n",
    "    sr.append(i)\n",
    "for i in s_2r:\n",
    "    sr.append(i)\n",
    "for i in s_3r:\n",
    "    sr.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fa1a5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sr:\n",
    "    a_set.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2e5dd21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{AUX -> 'will',\n",
       " DET -> 'the',\n",
       " Det -> 'a',\n",
       " Det -> 'the',\n",
       " N -> 'Homer',\n",
       " N -> 'Marge',\n",
       " N -> 'donut',\n",
       " N -> 'ham',\n",
       " N -> 'sandwich',\n",
       " N -> 'table',\n",
       " NP -> DET N,\n",
       " NP -> Det N,\n",
       " NP -> Det N N,\n",
       " NP -> N,\n",
       " NP -> NP PP,\n",
       " PP -> 'on' NP,\n",
       " S -> AUX NP VP,\n",
       " S -> NP AUX VP,\n",
       " S -> NP VP,\n",
       " V -> 'ate',\n",
       " V -> 'make',\n",
       " VP -> V NP}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c588ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "more_r = []\n",
    "more_r = list(a_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "638dca05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[N -> 'Homer',\n",
       " V -> 'ate',\n",
       " PP -> 'on' NP,\n",
       " AUX -> 'will',\n",
       " Det -> 'a',\n",
       " N -> 'sandwich',\n",
       " S -> NP VP,\n",
       " N -> 'ham',\n",
       " NP -> Det N,\n",
       " NP -> DET N,\n",
       " NP -> N,\n",
       " VP -> V NP,\n",
       " V -> 'make',\n",
       " NP -> Det N N,\n",
       " NP -> NP PP,\n",
       " N -> 'donut',\n",
       " N -> 'table',\n",
       " N -> 'Marge',\n",
       " S -> AUX NP VP,\n",
       " S -> NP AUX VP,\n",
       " DET -> 'the',\n",
       " Det -> 'the']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10d7808",
   "metadata": {},
   "source": [
    "c. Add the additional rules to your grammar1's production rules, using the .extend() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49abce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "Grammar_1.productions().extend(list(more_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec5f936",
   "metadata": {},
   "source": [
    "Marge will make a ham sandwich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9834c228",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = word_tokenize(\"\")\n",
    "par = nltk.ChartParser(Grammar_1)\n",
    "for i in par.parse(results):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78cd25d",
   "metadata": {},
   "source": [
    "d. And then, you have to re-initialize the grammar using the extended production rules (highlighted part). An illustration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "470e97a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar3 = nltk.CFG.fromstring(\"\"\" \n",
    "S -> NP VP\n",
    "NP -> N\n",
    "VP -> V\n",
    "N -> 'Homer'\n",
    "V -> 'sleeps'\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c902119d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar with 5 productions (start state = S)\n",
      "    S -> NP VP\n",
      "    NP -> N\n",
      "    VP -> V\n",
      "    N -> 'Homer'\n",
      "    V -> 'sleeps'\n"
     ]
    }
   ],
   "source": [
    "print(grammar3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18d6bce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[N -> 'Homer',\n",
       " V -> 'ate',\n",
       " PP -> 'on' NP,\n",
       " AUX -> 'will',\n",
       " Det -> 'a',\n",
       " N -> 'sandwich',\n",
       " S -> NP VP,\n",
       " N -> 'ham',\n",
       " NP -> Det N,\n",
       " NP -> DET N,\n",
       " NP -> N,\n",
       " VP -> V NP,\n",
       " V -> 'make',\n",
       " NP -> Det N N,\n",
       " NP -> NP PP,\n",
       " N -> 'donut',\n",
       " N -> 'table',\n",
       " N -> 'Marge',\n",
       " S -> AUX NP VP,\n",
       " S -> NP AUX VP,\n",
       " DET -> 'the',\n",
       " Det -> 'the']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c56a91d",
   "metadata": {},
   "source": [
    "e. Now, rebuild your chart parser with the updated grammar1. And try parsing the three sentences. It should successfully parse them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "862dea95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar with 27 productions (start state = S)\n",
      "    S -> NP VP\n",
      "    NP -> N\n",
      "    VP -> V\n",
      "    N -> 'Homer'\n",
      "    V -> 'sleeps'\n",
      "    N -> 'Homer'\n",
      "    V -> 'ate'\n",
      "    PP -> 'on' NP\n",
      "    AUX -> 'will'\n",
      "    Det -> 'a'\n",
      "    N -> 'sandwich'\n",
      "    S -> NP VP\n",
      "    N -> 'ham'\n",
      "    NP -> Det N\n",
      "    NP -> DET N\n",
      "    NP -> N\n",
      "    VP -> V NP\n",
      "    V -> 'make'\n",
      "    NP -> Det N N\n",
      "    NP -> NP PP\n",
      "    N -> 'donut'\n",
      "    N -> 'table'\n",
      "    N -> 'Marge'\n",
      "    S -> AUX NP VP\n",
      "    S -> NP AUX VP\n",
      "    DET -> 'the'\n",
      "    Det -> 'the'\n"
     ]
    }
   ],
   "source": [
    "grammar3.productions().extend(more_r)\n",
    "grammer3 = nltk.grammar.CFG(grammar3.start(), grammar3.productions())\n",
    "print(grammer3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c93a518",
   "metadata": {},
   "source": [
    "5.Try parsing another sentence of your own that is covered by the newly extended grammar1. Are you satisfied with the result?. Also, compare the result with other parsers – Recursive Descent Parser and Shift Reduce Parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d099ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Grammar_1 = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP | NP VP \n",
    "NP -> N | Det N | PRO | N N \n",
    "VP -> V NP CP | VP ADVP | V NP \n",
    "ADVP -> ADV ADV \n",
    "CP -> COMP S \n",
    "N -> 'Lisa' | 'brother' | 'peanut' | 'butter' \n",
    "V -> 'told' | 'liked' \n",
    "COMP -> 'that' \n",
    "Det -> 'her' \n",
    "PRO -> 'she' \n",
    "ADV -> 'very' | 'much'\n",
    "S -> NP VP \n",
    "NP -> NP CONJ NP | N | NP PP | Det N | N | Det N \n",
    "VP -> VP PP | VP CONJ VP | V | V \n",
    "PP -> P NP | P NP \n",
    "N -> 'Homer' | 'friends' | 'work' | 'bar' \n",
    "V -> 'drank' | 'sang' \n",
    "CONJ -> 'and' | 'and'\n",
    "Det -> 'his' | 'the'\n",
    "P -> 'from' | 'in'\n",
    "S -> NP VP \n",
    "NP -> NP CONJ NP | N | N \n",
    "VP -> V ADJP \n",
    "ADJP -> ADJP CONJ ADJP | ADJ | ADV ADJ \n",
    "N -> 'Homer' | 'Marge' \n",
    "V -> 'are' \n",
    "CONJ -> 'and' | 'but'\n",
    "ADJ -> 'poor' | 'happy'\n",
    "ADV -> 'very'\n",
    "S -> NP VP | NP AUX VP \n",
    "NP -> PRO | NP CP | Det N | PRO | PRO | PRO | N |Det N\n",
    "VP -> V NP PP | V NP NP\n",
    "CP -> COMP S\n",
    "PP -> P NP \n",
    "Det -> 'the' | 'his' \n",
    "PRO -> 'he' | 'I' | 'him' \n",
    "N -> 'book' | 't' | 'sister' \n",
    "V -> 'gave' | 'given' \n",
    "COMP -> 'that'\n",
    "AUX -> 'had' \n",
    "P -> 'to'\n",
    "S -> NP VP\n",
    "NP -> PRO | Det N | Det N\n",
    "VP -> V NP PP\n",
    "PP -> P NP \n",
    "Det -> 'the' | 'his'\n",
    "PRO -> 'he' \n",
    "N -> 'book' | 'sister' \n",
    "V -> 'gave' \n",
    "P -> 'to'\n",
    "S -> NP VP\n",
    "NP -> Det ADJ N | Det ADJ ADJ N | N\n",
    "VP -> V NP|VP PP\n",
    "PP -> P NP \n",
    "Det -> 'the' | 'the'\n",
    "ADJ -> 'big' | 'tiny' | 'nerdy'\n",
    "N -> 'bully' | 'kid' | 'school'\n",
    "V -> 'punched'\n",
    "P -> 'after'\n",
    "S -> NP AUX VP\n",
    "NP -> N | Det N N\n",
    "VP -> V NP\n",
    "N -> 'Marge' | 'ham' | 'sandwich'\n",
    "AUX -> 'will'\n",
    "V -> 'make'\n",
    "Det -> 'a'\n",
    "S -> AUX NP VP\n",
    "NP -> N | Det N N \n",
    "VP -> V NP\n",
    "N -> 'Marge'\n",
    "V -> 'make'\n",
    "AUX -> 'will'\n",
    "Det -> 'a'\n",
    "N -> 'Marge' | 'ham' | 'sandwich'\n",
    "S -> NP VP\n",
    "NP -> N | NP PP | Det N | Det N\n",
    "PP -> P NP\n",
    "VP -> V NP\n",
    "N -> 'Homer' | 'donut' | 'table'\n",
    "V -> 'ate'\n",
    "Det -> 'the' | 'the'\n",
    "P -> 'on'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46bd317e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (AUX will)\n",
      "  (NP (N Marge))\n",
      "  (VP (V make) (NP (Det a) (N ham) (N sandwich))))\n",
      "(S\n",
      "  (AUX will)\n",
      "  (NP (N Marge))\n",
      "  (VP (V make) (NP (Det a) (N ham)) (NP (N sandwich))))\n"
     ]
    }
   ],
   "source": [
    "sent = word_tokenize(\"will Marge make a ham sandwich\")\n",
    "par = nltk.ChartParser(Grammar_1)\n",
    "for i in par.parse(sent):\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944988e8",
   "metadata": {},
   "source": [
    "5.Try parsing another sentence of your own that is covered by the newly extended grammar1. Are you satisfied with the result?. Also,compare the result with other parsers – Recursive Descent Parser and Shift Reduce Parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c504b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sen = word_tokenize(\"will Marge make a ham sandwich\")\n",
    "#rd_par = nltk.RecursiveDescentParser(Grammar_1)\n",
    "#for tree in rd_par.parse(sen):\n",
    "#print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a485fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sent = word_tokenize(\"will Marge make a ham sandwich\")\n",
    "#sr_par = nltk.ShiftReduceParser(Grammar_1)\n",
    "#for tree in rd_par.parse(sent):\n",
    " #print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43599831",
   "metadata": {},
   "source": [
    "6.As the final step, pickle your grammar1 as lab12_grammar.pkl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3155ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('lab12_grammar.pkl', 'wb') as f:\n",
    "    pickle.dump(Grammar_1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058fb874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
